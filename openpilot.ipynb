{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97dc601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surya/.pyenv/versions/3.8.10/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7237bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IDXS = np.array([ 0. ,   0.1875,   0.75  ,   1.6875,   3.    ,   4.6875,\n",
    "                    6.75  ,   9.1875,  12.    ,  15.1875,  18.75  ,  22.6875,\n",
    "                    27.    ,  31.6875,  36.75  ,  42.1875,  48.    ,  54.1875,\n",
    "                    60.75  ,  67.6875,  75.    ,  82.6875,  90.75  ,  99.1875,\n",
    "                    108.    , 117.1875, 126.75  , 136.6875, 147.    , 157.6875,\n",
    "                    168.75  , 180.1875, 192.])\n",
    "def parse_image(frame):\n",
    "\tH = (frame.shape[0]*2)//3\n",
    "\tW = frame.shape[1]\n",
    "\tparsed = np.zeros((6, H//2, W//2), dtype=np.uint8)\n",
    "\tparsed[0] = frame[0:H:2, 0::2]\n",
    "\tparsed[1] = frame[1:H:2, 0::2]\n",
    "\tparsed[2] = frame[0:H:2, 1::2]\n",
    "\tparsed[3] = frame[1:H:2, 1::2]\n",
    "\tparsed[4] = frame[H:H+H//4].reshape((-1, H//2,W//2))\n",
    "\tparsed[5] = frame[H+H//4:H+H//2].reshape((-1, H//2,W//2))\n",
    "\treturn parsed\n",
    "def seperate_points_and_std_values(df):\n",
    "\tpoints = df.iloc[lambda x: x.index % 2 == 0]\n",
    "\tstd = df.iloc[lambda x: x.index % 2 != 0]\n",
    "\tpoints = pd.concat([points], ignore_index = True)\n",
    "\tstd = pd.concat([std], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d7d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"supercombo.onnx\"\n",
    "cap = cv2.VideoCapture('data/cropped_mini.mp4')\n",
    "parsed_images = []\n",
    "width = 512\n",
    "height = 256\n",
    "dim = (width, height)\n",
    "plan_start_idx = 0\n",
    "plan_end_idx = 4955\n",
    "lanes_start_idx = plan_end_idx\n",
    "lanes_end_idx = lanes_start_idx + 528\n",
    "lane_lines_prob_start_idx = lanes_end_idx\n",
    "lane_lines_prob_end_idx = lane_lines_prob_start_idx + 8\n",
    "road_start_idx = lane_lines_prob_end_idx\n",
    "road_end_idx = road_start_idx + 264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddc78d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This ORT build has ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], ...)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[43monnxruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(cap\u001b[38;5;241m.\u001b[39misOpened()):\n\u001b[1;32m      3\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:375\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m providers \u001b[38;5;241m==\u001b[39m [] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(available_providers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_fallback()\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis ORT build has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m enabled. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(available_providers)\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince ORT 1.9, you are required to explicitly set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe providers parameter when instantiating InferenceSession. For example, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxruntime.InferenceSession(..., providers=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(available_providers)\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    382\u001b[0m session_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01melse\u001b[39;00m C\u001b[38;5;241m.\u001b[39mget_default_session_options()\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path:\n",
      "\u001b[0;31mValueError\u001b[0m: This ORT build has ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], ...)"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(model, None)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if (ret == False):\n",
    "        break\n",
    "    if frame is not None:\n",
    "        img = cv2.resize(frame, dim)\n",
    "        img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV_I420)\n",
    "        parsed = parse_image(img_yuv)\n",
    "    if (len(parsed_images) >= 2):\n",
    "        del parsed_images[0]\n",
    "    parsed_images.append(parsed)\n",
    "    if (len(parsed_images) >= 2):\n",
    "        parsed_arr = np.array(parsed_images)\n",
    "        parsed_arr.resize((1,12,128,256))\n",
    "        data = json.dumps({'data': parsed_arr.tolist()})\n",
    "        data = np.array(json.loads(data)['data']).astype('float32')\n",
    "        input_imgs = session.get_inputs()[0].name\n",
    "        desire = session.get_inputs()[1].name\n",
    "        initial_state = session.get_inputs()[2].name\n",
    "        traffic_convention = session.get_inputs()[3].name\n",
    "        output_name = session.get_outputs()[0].name\n",
    "        desire_data = np.array([0]).astype('float32')\n",
    "        desire_data.resize((1,8))\n",
    "        initial_state_data = np.array([0]).astype('float32')\n",
    "        initial_state_data.resize((1,512))\n",
    "        traffic_convention_data = np.array([0]).astype('float32')\n",
    "        traffic_convention_data.resize((1,2))\n",
    "        result = session.run([output_name], {input_imgs: data,\n",
    "                                            desire: desire_data,\n",
    "                                            traffic_convention: traffic_convention_data,\n",
    "                                            initial_state: initial_state_data\n",
    "                                            })\n",
    "        res = np.array(result)\n",
    "        lanes = res[:,:,lanes_start_idx:lanes_end_idx]\n",
    "        lane_road = res[:,:,road_start_idx:road_end_idx]\n",
    "        lanes_flat = lanes.flatten()\n",
    "        df_lanes = pd.DataFrame(lanes_flat)\n",
    "        ll_t = df_lanes[0:66]\n",
    "        ll_t2 = df_lanes[66:132]\n",
    "        points_ll_t, std_ll_t = seperate_points_and_std_values(ll_t)\n",
    "        points_ll_t2, std_ll_t2 = seperate_points_and_std_values(ll_t2)\n",
    "        l_t = df_lanes[132:198]\n",
    "        l_t2 = df_lanes[198:264]\n",
    "        points_l_t, std_l_t = seperate_points_and_std_values(l_t)\n",
    "        points_l_t2, std_l_t2 = seperate_points_and_std_values(l_t2)\n",
    "        r_t = df_lanes[264:330]\n",
    "        r_t2 = df_lanes[330:396]\n",
    "        points_r_t, std_r_t = seperate_points_and_std_values(r_t)\n",
    "        points_r_t2, std_r_t2 = seperate_points_and_std_values(r_t2)\n",
    "        rr_t = df_lanes[396:462]\n",
    "        rr_t2 = df_lanes[462:528]\n",
    "        points_rr_t, std_rr_t = seperate_points_and_std_values(rr_t)\n",
    "        points_rr_t2, std_rr_t2 = seperate_points_and_std_values(rr_t2)\n",
    "        road_flat = lane_road.flatten()\n",
    "        df_road = pd.DataFrame(road_flat)\n",
    "        roadr_t = df_road[0:66]\n",
    "        roadr_t2 = df_road[66:132]\n",
    "        points_road_t, std_ll_t = seperate_points_and_std_values(roadr_t)\n",
    "        points_road_t2, std_ll_t2 = seperate_points_and_std_values(roadr_t2)\n",
    "        roadl_t = df_road[132:198]\n",
    "        roadl_t2 = df_road[198:264]\n",
    "        points_roadl_t, std_rl_t = seperate_points_and_std_values(roadl_t)\n",
    "        points_roadl_t2, std_rl_t2 = seperate_points_and_std_values(roadl_t2)\n",
    "        middle = points_ll_t2.add(points_l_t, fill_value=0) / 2\n",
    "        plt.scatter(middle, X_IDXS, color = \"g\")\n",
    "        plt.scatter(points_ll_t2, X_IDXS, color = \"y\")\n",
    "        plt.scatter(points_l_t, X_IDXS, color = \"y\")\n",
    "        plt.scatter(points_road_t, X_IDXS, color = \"r\")\n",
    "        plt.scatter(points_road_t2, X_IDXS, color = \"r\")\n",
    "        plt.title(\"Raod lines\")\n",
    "        plt.xlabel(\"red - road lines | green - predicted path | yellow - lane lines\")\n",
    "        plt.ylabel(\"Range\")\n",
    "        plt.show()\n",
    "        plt.pause(0.1)\n",
    "        plt.clf()\n",
    "    frame = cv2.resize(frame, (900, 500))\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647db67-856b-4c56-a538-b5347f7abd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d873b291d4e94f17dcd12f6c2f1d97938a7ce7335e199a83faefae9e210ac59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
